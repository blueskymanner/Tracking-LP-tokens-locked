{"ast":null,"code":"import { GraphQLError as e } from \"graphql/error/GraphQLError.mjs\";\nimport { Kind as r } from \"graphql/language/kinds.mjs\";\nimport { parse as t } from \"graphql/language/parser.mjs\";\nimport { print as n } from \"graphql/language/printer.mjs\";\nimport { make as o } from \"wonka\";\n\nfunction rehydrateGraphQlError(r) {\n  if (\"string\" == typeof r) {\n    return new e(r);\n  } else if (\"object\" == typeof r && r.message) {\n    return new e(r.message, r.nodes, r.source, r.positions, r.path, r, r.extensions || {});\n  } else {\n    return r;\n  }\n}\n\nvar a = function (e) {\n  function CombinedError(r) {\n    var t = r.networkError;\n    var n = r.response;\n    var o = (r.graphQLErrors || []).map(rehydrateGraphQlError);\n\n    var a = function generateErrorMessage(e, r) {\n      var t = \"\";\n\n      if (void 0 !== e) {\n        return t = \"[Network] \" + e.message;\n      }\n\n      if (void 0 !== r) {\n        r.forEach(function (e) {\n          t += \"[GraphQL] \" + e.message + \"\\n\";\n        });\n      }\n\n      return t.trim();\n    }(t, o);\n\n    e.call(this, a);\n    this.name = \"CombinedError\";\n    this.message = a;\n    this.graphQLErrors = o;\n    this.networkError = t;\n    this.response = n;\n  }\n\n  if (e) {\n    CombinedError.__proto__ = e;\n  }\n\n  (CombinedError.prototype = Object.create(e && e.prototype)).constructor = CombinedError;\n\n  CombinedError.prototype.toString = function toString() {\n    return this.message;\n  };\n\n  return CombinedError;\n}(Error);\n\nfunction phash(e, r) {\n  e |= 0;\n\n  for (var t = 0, n = 0 | r.length; t < n; t++) {\n    e = (e << 5) + e + r.charCodeAt(t);\n  }\n\n  return e;\n}\n\nfunction hash(e) {\n  return phash(5381, e) >>> 0;\n}\n\nvar i = new Set();\nvar s = new WeakMap();\n\nfunction stringify(e) {\n  if (null === e || i.has(e)) {\n    return \"null\";\n  } else if (\"object\" != typeof e) {\n    return JSON.stringify(e) || \"\";\n  } else if (e.toJSON) {\n    return stringify(e.toJSON());\n  } else if (Array.isArray(e)) {\n    var r = \"[\";\n\n    for (var t = 0, n = e.length; t < n; t++) {\n      if (t > 0) {\n        r += \",\";\n      }\n\n      var o = stringify(e[t]);\n      r += o.length > 0 ? o : \"null\";\n    }\n\n    return r += \"]\";\n  }\n\n  var a = Object.keys(e).sort();\n\n  if (!a.length && e.constructor && e.constructor !== Object) {\n    var u = s.get(e) || Math.random().toString(36).slice(2);\n    s.set(e, u);\n    return '{\"__key\":\"' + u + '\"}';\n  }\n\n  i.add(e);\n  var f = \"{\";\n\n  for (var c = 0, l = a.length; c < l; c++) {\n    var h = a[c];\n    var p = stringify(e[h]);\n\n    if (p) {\n      if (f.length > 1) {\n        f += \",\";\n      }\n\n      f += stringify(h) + \":\" + p;\n    }\n  }\n\n  i.delete(e);\n  return f += \"}\";\n}\n\nfunction stringifyVariables(e) {\n  i.clear();\n  return stringify(e);\n}\n\nfunction stringifyDocument(e) {\n  var r = (\"string\" != typeof e ? e.loc && e.loc.source.body || n(e) : e).replace(/([\\s,]|#[^\\n\\r]+)+/g, \" \").trim();\n\n  if (\"string\" != typeof e) {\n    var t = \"definitions\" in e && getOperationName(e);\n\n    if (t) {\n      r = \"# \" + t + \"\\n\" + r;\n    }\n\n    if (!e.loc) {\n      e.loc = {\n        start: 0,\n        end: r.length,\n        source: {\n          body: r,\n          name: \"gql\",\n          locationOffset: {\n            line: 1,\n            column: 1\n          }\n        }\n      };\n    }\n  }\n\n  return r;\n}\n\nvar u = new Map();\n\nfunction keyDocument(e) {\n  var r;\n  var n;\n\n  if (\"string\" == typeof e) {\n    r = hash(stringifyDocument(e));\n    n = u.get(r) || t(e, {\n      noLocation: !0\n    });\n  } else {\n    r = e.__key || hash(stringifyDocument(e));\n    n = u.get(r) || e;\n  }\n\n  if (!n.loc) {\n    stringifyDocument(n);\n  }\n\n  n.__key = r;\n  u.set(r, n);\n  return n;\n}\n\nfunction createRequest(e, r) {\n  if (!r) {\n    r = {};\n  }\n\n  var t = keyDocument(e);\n  return {\n    key: phash(t.__key, stringifyVariables(r)) >>> 0,\n    query: t,\n    variables: r\n  };\n}\n\nfunction getOperationName(e) {\n  for (var t = 0, n = e.definitions.length; t < n; t++) {\n    var o = e.definitions[t];\n\n    if (o.kind === r.OPERATION_DEFINITION && o.name) {\n      return o.name.value;\n    }\n  }\n}\n\nfunction getOperationType(e) {\n  for (var t = 0, n = e.definitions.length; t < n; t++) {\n    var o = e.definitions[t];\n\n    if (o.kind === r.OPERATION_DEFINITION) {\n      return o.operation;\n    }\n  }\n}\n\nfunction _extends() {\n  return (_extends = Object.assign || function (e) {\n    for (var r = 1; r < arguments.length; r++) {\n      var t = arguments[r];\n\n      for (var n in t) {\n        if (Object.prototype.hasOwnProperty.call(t, n)) {\n          e[n] = t[n];\n        }\n      }\n    }\n\n    return e;\n  }).apply(this, arguments);\n}\n\nfunction makeResult(e, r, t) {\n  if (!(\"data\" in r) && !(\"errors\" in r) || \"path\" in r) {\n    throw new Error(\"No Content\");\n  }\n\n  return {\n    operation: e,\n    data: r.data,\n    error: Array.isArray(r.errors) ? new a({\n      graphQLErrors: r.errors,\n      response: t\n    }) : void 0,\n    extensions: \"object\" == typeof r.extensions && r.extensions || void 0,\n    hasNext: !!r.hasNext\n  };\n}\n\nfunction mergeResultPatch(e, r, t) {\n  var n = _extends({}, e);\n\n  n.hasNext = !!r.hasNext;\n\n  if (!(\"path\" in r)) {\n    if (\"data\" in r) {\n      n.data = r.data;\n    }\n\n    return n;\n  }\n\n  if (Array.isArray(r.errors)) {\n    n.error = new a({\n      graphQLErrors: n.error ? n.error.graphQLErrors.concat(r.errors) : r.errors,\n      response: t\n    });\n  }\n\n  var o = n.data = _extends({}, n.data);\n\n  var i = 0;\n  var s;\n\n  while (i < r.path.length) {\n    o = o[s = r.path[i++]] = Array.isArray(o[s]) ? [].concat(o[s]) : _extends({}, o[s]);\n  }\n\n  _extends(o, r.data);\n\n  return n;\n}\n\nfunction makeErrorResult(e, r, t) {\n  return {\n    operation: e,\n    data: void 0,\n    error: new a({\n      networkError: r,\n      response: t\n    }),\n    extensions: void 0\n  };\n}\n\nfunction shouldUseGet(e) {\n  return \"query\" === e.kind && !!e.context.preferGetMethod;\n}\n\nfunction makeFetchBody(e) {\n  return {\n    query: n(e.query),\n    operationName: getOperationName(e.query),\n    variables: e.variables || void 0,\n    extensions: void 0\n  };\n}\n\nfunction makeFetchURL(e, r) {\n  var t = shouldUseGet(e);\n  var n = e.context.url;\n\n  if (!t || !r) {\n    return n;\n  }\n\n  var o = [];\n\n  if (r.operationName) {\n    o.push(\"operationName=\" + encodeURIComponent(r.operationName));\n  }\n\n  if (r.query) {\n    o.push(\"query=\" + encodeURIComponent(r.query.replace(/#[^\\n\\r]+/g, \" \").trim()));\n  }\n\n  if (r.variables) {\n    o.push(\"variables=\" + encodeURIComponent(stringifyVariables(r.variables)));\n  }\n\n  if (r.extensions) {\n    o.push(\"extensions=\" + encodeURIComponent(stringifyVariables(r.extensions)));\n  }\n\n  return n + \"?\" + o.join(\"&\");\n}\n\nfunction makeFetchOptions(e, r) {\n  var t = shouldUseGet(e);\n  var n = \"function\" == typeof e.context.fetchOptions ? e.context.fetchOptions() : e.context.fetchOptions || {};\n  return _extends({}, n, {\n    body: !t && r ? JSON.stringify(r) : void 0,\n    method: t ? \"GET\" : \"POST\",\n    headers: t ? n.headers : _extends({}, {\n      \"content-type\": \"application/json\"\n    }, n.headers)\n  });\n}\n\nvar f = \"undefined\" != typeof Symbol ? Symbol.asyncIterator : null;\nvar c = \"undefined\" != typeof TextDecoder ? new TextDecoder() : null;\nvar l = /content-type:[^\\r\\n]*application\\/json/i;\nvar h = /boundary=\"?([^=\";]+)\"?/i;\n\nfunction executeIncrementalFetch(e, r, t) {\n  var n = t.headers && t.headers.get(\"Content-Type\") || \"\";\n\n  if (!/multipart\\/mixed/i.test(n)) {\n    return t.json().then(function (n) {\n      e(makeResult(r, n, t));\n    });\n  }\n\n  var o = \"---\";\n  var a = n.match(h);\n\n  if (a) {\n    o = \"--\" + a[1];\n  }\n\n  var i;\n\n  var cancel = function () {};\n\n  if (f && t[f]) {\n    var s = t[f]();\n    i = s.next.bind(s);\n  } else if (\"body\" in t && t.body) {\n    var u = t.body.getReader();\n    cancel = u.cancel.bind(u);\n    i = u.read.bind(u);\n  } else {\n    throw new TypeError(\"Streaming requests unsupported\");\n  }\n\n  var p = \"\";\n  var d = !0;\n  var m = null;\n  var v = null;\n  return i().then(function next(n) {\n    if (!n.done) {\n      var a = function toString(e) {\n        return \"Buffer\" === e.constructor.name ? e.toString() : c.decode(e);\n      }(n.value);\n\n      var s = a.indexOf(o);\n\n      if (s > -1) {\n        s += p.length;\n      } else {\n        s = p.indexOf(o);\n      }\n\n      p += a;\n\n      while (s > -1) {\n        var u = p.slice(0, s);\n        var f = p.slice(s + o.length);\n\n        if (d) {\n          d = !1;\n        } else {\n          var h = u.indexOf(\"\\r\\n\\r\\n\") + 4;\n          var g = u.slice(0, h);\n          var y = u.slice(h, u.lastIndexOf(\"\\r\\n\"));\n          var x = void 0;\n\n          if (l.test(g)) {\n            try {\n              x = JSON.parse(y);\n              m = v = v ? mergeResultPatch(v, x, t) : makeResult(r, x, t);\n            } catch (e) {}\n          }\n\n          if (\"--\" === f.slice(0, 2) || x && !x.hasNext) {\n            if (!v) {\n              return e(makeResult(r, {}, t));\n            }\n\n            break;\n          }\n        }\n\n        s = (p = f).indexOf(o);\n      }\n    }\n\n    if (m) {\n      e(m);\n      m = null;\n    }\n\n    if (!n.done && (!v || v.hasNext)) {\n      return i().then(next);\n    }\n  }).finally(cancel);\n}\n\nfunction makeFetchSource(e, r, t) {\n  var n = \"manual\" === t.redirect ? 400 : 300;\n  var a = e.context.fetch;\n  return o(function (o) {\n    var i = o.next;\n    var s = o.complete;\n    var u = \"undefined\" != typeof AbortController ? new AbortController() : null;\n\n    if (u) {\n      t.signal = u.signal;\n    }\n\n    var f = !1;\n    var c = !1;\n    var l;\n    Promise.resolve().then(function () {\n      if (f) {\n        return;\n      }\n\n      return (a || fetch)(r, t);\n    }).then(function (r) {\n      if (!r) {\n        return;\n      }\n\n      c = (l = r).status < 200 || l.status >= n;\n      return executeIncrementalFetch(i, e, l);\n    }).then(s).catch(function (r) {\n      if (\"AbortError\" !== r.name) {\n        var t = makeErrorResult(e, c ? new Error(l.statusText) : r, l);\n        i(t);\n        s();\n      }\n    });\n    return function () {\n      f = !0;\n\n      if (u) {\n        u.abort();\n      }\n    };\n  });\n}\n\nexport { a as C, _extends as _, makeErrorResult as a, makeFetchBody as b, makeFetchURL as c, makeFetchOptions as d, makeFetchSource as e, createRequest as f, getOperationType as g, stringifyVariables as h, mergeResultPatch as i, getOperationName as j, keyDocument as k, makeResult as m, stringifyDocument as s };","map":{"version":3,"sources":["../src/utils/error.ts","../src/utils/hash.ts","../src/utils/stringifyVariables.ts","../src/utils/request.ts","../src/utils/result.ts","../src/internal/fetchOptions.ts","../src/internal/fetchSource.ts"],"names":["generateErrorMessage","rehydrateGraphQlError","message","super","response","h","const","hash","stringify","seen","x","let","i","Array","out","l$1","stringifyDocument","loc","key","noLocation","q","getOperationType","query","l","definitions","length","node","kind","Kind","OPERATION_DEFINITION","operation","result","extensions","Error","patch","CombinedError","path","prop","data","error","part","shouldUseGet","variables","makeFetchURL","request","body","push","encodeURIComponent","useGETMethod","name","test","onResult","boundary","cancel","prevResult","next","getReader","indexOf","buffer","_error","payload","fetcher","complete","catch"],"mappings":";;;kBAEMA,C,QAAAA,8B;;;AAqBH,SAAMC,qBAAN,CAAMA,CAAN,EAAMA;;;;;;;;;;;;QAmCCC,CAAAA,GAAAA,CAAAA,CAAAA,Y;;eAENC,a,IAAAA,E,EAAAA,G,CAAAA,qB;;YArDF,SAAA,oBAAA,CAAA,CAAA,EAAA,CAAA,EAAA;;;;;;;;;;;;;aAaIF,CAAAA,CAAAA,IAAAA,E;KAbJ,C,CAAA,E,CAAA,C;;iBA0DEC,C;SACKE,I,GAAAA,e;;;;;;;;;;;iBAIOF,S,GAAAA,MAAAA,CAAAA,MAAAA,CAAAA,CAAAA,IAAAA,CAAAA,CAAAA,SAAAA,C,EAAAA,W,GAAAA,a;;;;;;;;;AChEZG,SAAKA,KAALA,CAAIA,CAAJA,EAAIA,CAAJA,EAAIA;;;;;;;;;;ACLRC,SAAWC,IAAXD,CAAWC,CAAXD,EAAWC;;;;AAIP,IAAA,CAAA,GAAO,IAAA,GAAA,EAAP;AACD,IAAA,CAAA,GAAA,IAAA,OAAA,EAAA;;AAEA,SAAMC,SAAN,CAAMA,CAAN,EAAMA;oBACWC,CAAAA,CAAAA,GAAAA,CAACC,CAADD,C,EAACC;;;;SAGZC,IAAIC,CAAAA,CAAAA,MAAJD,EAAIC;WACFJ,SAAAA,CAAAA,CAAAA,CAAAA,MAAAA,EAAAA,C;GADFG,M,IACWE,KAAAA,CAAAA,OAAAA,CAAAA,CAAAA,C,EAAAA;;;;AAEdC,UAAAA,CAAAA,GAAAA,CAAAA,EAAAA;;;;;;;;;;;;;;;;;;;;;;kBAoBIC,CAAAA,GAAAA,CAAAA,CAAAA,M,EAAAA,CAAAA,GAAAA,C,EAAAA,CAAAA,E,EAAAA;QAAgBD,CAAAA,GAAAA,CAAAA,CAAAA,CAAAA,C;;;;;;;;;;;;;SAWxBL,CAAAA,IAAAA,G;;;SCvBWO,kB,CAAAA,C,EAAAA;;;;;;;;;;;;;;;WAqBCC,G,EAAAA;;;;;;;;;;;;;;;;;;;AAiBVC,IAAAA,CAAAA,GAAAA,IAAWF,GAAXE,EAAAA;;AACoCC,SAAAA,WAAAA,CAAAA,CAAAA,EAAAA;MAApCD,C;;;4BAGyBE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;SAuChBC,gB,CAAoBC,C,EAAAA;OAC1BX,IAAIC,CAAAA,GAAI,CAARD,EAAWY,CAAAA,GAAID,CAAAA,CAAME,WAANF,CAAkBG,M,EAAQb,CAAAA,GAAIW,C,EAAGX,CAAAA,E,EAAK;QAClDc,CAAAA,GAAOJ,CAAAA,CAAME,WAANF,CAAkBV,CAAlBU,C;;QACTI,CAAAA,CAAKC,IAALD,KAAcE,CAAAA,CAAKC,oBAAnBH,IAAmBG,CAAAA,CAAAA,I,EAAAA;aACdH,CAAAA,CAAKI,IAALJ,CAAKI,K;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;kBChGTC,C,KAAAA,EAAAA,YAAAA,CAAAA,C,IAAAA,UAAAA,C,EAAAA;AASLC,UAAAA,IAAUC,KAAVD,CAAUC,YAAVD,CAAAA;;;;;;;qBAYiBE,CAAAA,CAAAA,M;;;mCAGjBH,CAAAA,CAAAA,U,IAAAA,CAAAA,CAAAA,U,IAAAA,KAAAA,C;;;;;AAED,SAAA,gBAAA,CAAA,CAAA,EAAA,CAAA,EAAA,CAAA,EAAA;;;;;;;;;;;;;;cAiBgBK,IAAND,CAAMC,CAAND;qBACFJ,CAAAA,CAAAA,KAAAA,GAAAA,CAAAA,CAAAA,KAAAA,CAAAA,aAAAA,CAAAA,MAAAA,CAAAA,CAAAA,CAAAA,MAAAA,CAAAA,GAAAA,CAAAA,CAAAA,MADEI;gBAEGE;AAFHF,KAAMC,C;;;;;;;;oBAeIX,M,EAAAA;AAGrBc,IAAAA,CAAAA,GAAOC,CAAAA,CADPF,CAAAA,GAAAA,CAAAA,CAAAA,IAAAA,CAAAA,CAAAA,EAAAA,CACOE,CAAAA,GADPF,KAAAA,CAAAA,OAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,IAAAA,GAAAA,MAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,GAAAA,QAAAA,CAAAA,EAAAA,EAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CACAC;;;;;;;;SC7DIE,e,CAAAA,C,EAAAA,C,EAAAA,C,EAAAA;SACGX;gBAAAA;gBAAAA;;;gBAOK1B;MAPL0B;AASPY,IAAAA,UAAAA,EAAAA,KAAAA;AATOZ,G;;;SAaIa,Y,CACXb,C,EAAAA;;;;AAKA,SAAA,aAAA,CAAqBc,CAArB,EAAqBA;;;;eAEIA,CAAAA,CAAAA,SAAAA,IAAAA,KAAAA,C;;;;;;MAKrBC,CAAAA,GAAAA,YAAAA,CAAAA,CAAAA,C;;;;WAOKH,C;;;;;QAOAI,a,EAAAA;;;;;;;;;AAqBPD,IAAAA,CAAAA,CAAOG,IAAPH,CAAOG,eAADD,kBAAAA,CAAAA,kBAAAA,CAAAA,CAAAA,CAAAA,SAAAA,CAAAA,CAANF;;;;;;;;;;ACnEJvC,SAAAA,gBAAAA,CAAAA,CAAAA,EAAAA,CAAAA,EAAAA;;;;;gBAQoB2C,K,GAAAA,M;;;;;;;AAclB,IAAA,CAAA,GAAA,eAAA,OAAyBC,MAAzB,GAAyBA,MAAAA,CAAAA,aAAzB,GAAyBA,IAAzB;AACE,IAAA,CAAA,GAAA,eAAA,OAAA,WAAA,GAAA,IAAA,WAAA,EAAA,GAAA,IAAA;AACEC,IAAAA,CAAAA,GAAAA,yCAAAA;AACD,IAAA,CAAA,GAAA,yBAAA;;AAKiBC,SAAAA,uBAAAA,CAAAA,CAAAA,EAAAA,CAAAA,EAAAA,CAAAA,EAAAA;;;;;;;;;;;;;AAWlBC,IAAAA,CAAAA,GAAAA,OAAAA,CAAAA,CAAAA,CAAAA,CAAAA;;;;;;;MASEC,CAAAA,IAAJ3C,CAAAA,CAAAA,CAAAA,C,EAAAA;;QAES4C,CAAAA,CAATA,IAASA,CAATA,IAASA,CAATA,CAASA,C;SACFjB,IAAI,UAAA,CAAA,IAAA,CAAA,CAAA,IAAJA,EAAI;cACeO,I,CAAKW,S;2BACDC,C;;GAFvBnB,M;;;;;;MASHoB,CAAAA,GAAAA,I;;;;cAlCJ/C,SAAAA,QAAAA,CAAAA,CAAAA,EAAAA;;OAAAA,C,OAAAA,C;;;;;;;;;;;;;;gBAqDmBgD,CAAAA,CAAAA,KAAAA,CAAAA,CAAAA,GAAAA,CAAAA,CAAAA,MAAAA,C;;;;;;;;;;;;AAUPC,cAAAA,CAAAA,GAAAA,IAAAA,CAAAA,KAAAA,CAAAA,CAAAA,CAAAA;;;;;;;;;;;;;;;;;;;AAwBNC,MAAAA,CAAAA,CAAAA,CAAAA,CAAAA;;;;;;;;;;AAWJlD,SAAAA,eAAAA,CAAAA,CAAAA,EAAAA,CAAAA,EAAAA,CAAAA,EAAAA;;;;;;;;;;;;;;;YAaQmD,O,GACLC,I,CAZH,YAAA;UAaQxB,C,EAAAA","sourcesContent":["import { GraphQLError } from 'graphql';\n\nconst generateErrorMessage = (\n  networkErr?: Error,\n  graphQlErrs?: GraphQLError[]\n) => {\n  let error = '';\n  if (networkErr !== undefined) {\n    return (error = `[Network] ${networkErr.message}`);\n  }\n\n  if (graphQlErrs !== undefined) {\n    graphQlErrs.forEach(err => {\n      error += `[GraphQL] ${err.message}\\n`;\n    });\n  }\n\n  return error.trim();\n};\n\nconst rehydrateGraphQlError = (error: any): GraphQLError => {\n  if (typeof error === 'string') {\n    return new GraphQLError(error);\n  } else if (typeof error === 'object' && error.message) {\n    return new GraphQLError(\n      error.message,\n      error.nodes,\n      error.source,\n      error.positions,\n      error.path,\n      error,\n      error.extensions || {}\n    );\n  } else {\n    return error as any;\n  }\n};\n\n/** An error which can consist of GraphQL errors and Network errors. */\nexport class CombinedError extends Error {\n  public name: string;\n  public message: string;\n  public graphQLErrors: GraphQLError[];\n  public networkError?: Error;\n  public response?: any;\n\n  constructor({\n    networkError,\n    graphQLErrors,\n    response,\n  }: {\n    networkError?: Error;\n    graphQLErrors?: Array<string | Partial<GraphQLError> | Error>;\n    response?: any;\n  }) {\n    const normalizedGraphQLErrors = (graphQLErrors || []).map(\n      rehydrateGraphQlError\n    );\n    const message = generateErrorMessage(networkError, normalizedGraphQLErrors);\n\n    super(message);\n\n    this.name = 'CombinedError';\n    this.message = message;\n    this.graphQLErrors = normalizedGraphQLErrors;\n    this.networkError = networkError;\n    this.response = response;\n  }\n\n  toString() {\n    return this.message;\n  }\n}\n","// When we have separate strings it's useful to run a progressive\n// version of djb2 where we pretend that we're still looping over\n// the same string\nexport const phash = (h: number, x: string): number => {\n  h = h | 0;\n  for (let i = 0, l = x.length | 0; i < l; i++) {\n    h = (h << 5) + h + x.charCodeAt(i);\n  }\n\n  return h;\n};\n\n// This is a djb2 hashing function\nexport const hash = (x: string): number => phash(5381 | 0, x) >>> 0;\n","const seen = new Set();\nconst cache = new WeakMap();\n\nconst stringify = (x: any): string => {\n  if (x === null || seen.has(x)) {\n    return 'null';\n  } else if (typeof x !== 'object') {\n    return JSON.stringify(x) || '';\n  } else if (x.toJSON) {\n    return stringify(x.toJSON());\n  } else if (Array.isArray(x)) {\n    let out = '[';\n    for (let i = 0, l = x.length; i < l; i++) {\n      if (i > 0) out += ',';\n      const value = stringify(x[i]);\n      out += value.length > 0 ? value : 'null';\n    }\n\n    out += ']';\n    return out;\n  }\n\n  const keys = Object.keys(x).sort();\n  if (!keys.length && x.constructor && x.constructor !== Object) {\n    const key = cache.get(x) || Math.random().toString(36).slice(2);\n    cache.set(x, key);\n    return `{\"__key\":\"${key}\"}`;\n  }\n\n  seen.add(x);\n  let out = '{';\n  for (let i = 0, l = keys.length; i < l; i++) {\n    const key = keys[i];\n    const value = stringify(x[key]);\n    if (value) {\n      if (out.length > 1) out += ',';\n      out += stringify(key) + ':' + value;\n    }\n  }\n\n  seen.delete(x);\n  out += '}';\n  return out;\n};\n\nexport const stringifyVariables = (x: any): string => {\n  seen.clear();\n  return stringify(x);\n};\n","import { TypedDocumentNode } from '@graphql-typed-document-node/core';\n\nimport {\n  Location,\n  DefinitionNode,\n  DocumentNode,\n  Kind,\n  parse,\n  print,\n} from 'graphql';\n\nimport { hash, phash } from './hash';\nimport { stringifyVariables } from './stringifyVariables';\nimport { GraphQLRequest } from '../types';\n\ninterface WritableLocation {\n  loc: Location | undefined;\n}\n\nexport interface KeyedDocumentNode extends DocumentNode {\n  __key: number;\n}\n\nexport const stringifyDocument = (\n  node: string | DefinitionNode | DocumentNode\n): string => {\n  let str = (typeof node !== 'string'\n    ? (node.loc && node.loc.source.body) || print(node)\n    : node\n  )\n    .replace(/([\\s,]|#[^\\n\\r]+)+/g, ' ')\n    .trim();\n\n  if (typeof node !== 'string') {\n    const operationName = 'definitions' in node && getOperationName(node);\n    if (operationName) {\n      str = `# ${operationName}\\n${str}`;\n    }\n\n    if (!node.loc) {\n      (node as WritableLocation).loc = {\n        start: 0,\n        end: str.length,\n        source: {\n          body: str,\n          name: 'gql',\n          locationOffset: { line: 1, column: 1 },\n        },\n      } as Location;\n    }\n  }\n\n  return str;\n};\n\nconst docs = new Map<number, KeyedDocumentNode>();\n\nexport const keyDocument = (q: string | DocumentNode): KeyedDocumentNode => {\n  let key: number;\n  let query: DocumentNode;\n  if (typeof q === 'string') {\n    key = hash(stringifyDocument(q));\n    query = docs.get(key) || parse(q, { noLocation: true });\n  } else {\n    key = (q as KeyedDocumentNode).__key || hash(stringifyDocument(q));\n    query = docs.get(key) || q;\n  }\n\n  // Add location information if it's missing\n  if (!query.loc) stringifyDocument(query);\n\n  (query as KeyedDocumentNode).__key = key;\n  docs.set(key, query as KeyedDocumentNode);\n  return query as KeyedDocumentNode;\n};\n\nexport const createRequest = <Data = any, Variables = object>(\n  q: string | DocumentNode | TypedDocumentNode<Data, Variables>,\n  vars?: Variables\n): GraphQLRequest<Data, Variables> => {\n  if (!vars) vars = {} as Variables;\n  const query = keyDocument(q);\n  return {\n    key: phash(query.__key, stringifyVariables(vars)) >>> 0,\n    query,\n    variables: vars,\n  };\n};\n\n/**\n * Finds the Name value from the OperationDefinition of a Document\n */\nexport const getOperationName = (query: DocumentNode): string | undefined => {\n  for (let i = 0, l = query.definitions.length; i < l; i++) {\n    const node = query.definitions[i];\n    if (node.kind === Kind.OPERATION_DEFINITION && node.name) {\n      return node.name.value;\n    }\n  }\n};\n\n/**\n * Finds the operation-type\n */\nexport const getOperationType = (query: DocumentNode): string | undefined => {\n  for (let i = 0, l = query.definitions.length; i < l; i++) {\n    const node = query.definitions[i];\n    if (node.kind === Kind.OPERATION_DEFINITION) {\n      return node.operation;\n    }\n  }\n};\n","import { ExecutionResult, Operation, OperationResult } from '../types';\nimport { CombinedError } from './error';\n\nexport const makeResult = (\n  operation: Operation,\n  result: ExecutionResult,\n  response?: any\n): OperationResult => {\n  if ((!('data' in result) && !('errors' in result)) || 'path' in result) {\n    throw new Error('No Content');\n  }\n\n  return {\n    operation,\n    data: result.data,\n    error: Array.isArray(result.errors)\n      ? new CombinedError({\n          graphQLErrors: result.errors,\n          response,\n        })\n      : undefined,\n    extensions:\n      (typeof result.extensions === 'object' && result.extensions) || undefined,\n    hasNext: !!result.hasNext,\n  };\n};\n\nexport const mergeResultPatch = (\n  prevResult: OperationResult,\n  patch: ExecutionResult,\n  response?: any\n): OperationResult => {\n  const result = { ...prevResult };\n  result.hasNext = !!patch.hasNext;\n\n  if (!('path' in patch)) {\n    if ('data' in patch) result.data = patch.data;\n    return result;\n  }\n\n  if (Array.isArray(patch.errors)) {\n    result.error = new CombinedError({\n      graphQLErrors: result.error\n        ? [...result.error.graphQLErrors, ...patch.errors]\n        : patch.errors,\n      response,\n    });\n  }\n\n  let part: Record<string, any> | Array<any> = (result.data = {\n    ...result.data,\n  });\n\n  let i = 0;\n  let prop: string | number;\n  while (i < patch.path.length) {\n    prop = patch.path[i++];\n    part = part[prop] = Array.isArray(part[prop])\n      ? [...part[prop]]\n      : { ...part[prop] };\n  }\n\n  Object.assign(part, patch.data);\n  return result;\n};\n\nexport const makeErrorResult = (\n  operation: Operation,\n  error: Error,\n  response?: any\n): OperationResult => ({\n  operation,\n  data: undefined,\n  error: new CombinedError({\n    networkError: error,\n    response,\n  }),\n  extensions: undefined,\n});\n","import { DocumentNode, print } from 'graphql';\n\nimport { getOperationName, stringifyVariables } from '../utils';\nimport { Operation } from '../types';\n\nexport interface FetchBody {\n  query?: string;\n  operationName: string | undefined;\n  variables: undefined | Record<string, any>;\n  extensions: undefined | Record<string, any>;\n}\n\nconst shouldUseGet = (operation: Operation): boolean => {\n  return operation.kind === 'query' && !!operation.context.preferGetMethod;\n};\n\nexport const makeFetchBody = (request: {\n  query: DocumentNode;\n  variables?: object;\n}): FetchBody => ({\n  query: print(request.query),\n  operationName: getOperationName(request.query),\n  variables: request.variables || undefined,\n  extensions: undefined,\n});\n\nexport const makeFetchURL = (\n  operation: Operation,\n  body?: FetchBody\n): string => {\n  const useGETMethod = shouldUseGet(operation);\n  const url = operation.context.url;\n  if (!useGETMethod || !body) return url;\n\n  const search: string[] = [];\n  if (body.operationName) {\n    search.push('operationName=' + encodeURIComponent(body.operationName));\n  }\n\n  if (body.query) {\n    search.push(\n      'query=' +\n        encodeURIComponent(body.query.replace(/#[^\\n\\r]+/g, ' ').trim())\n    );\n  }\n\n  if (body.variables) {\n    search.push(\n      'variables=' + encodeURIComponent(stringifyVariables(body.variables))\n    );\n  }\n\n  if (body.extensions) {\n    search.push(\n      'extensions=' + encodeURIComponent(stringifyVariables(body.extensions))\n    );\n  }\n\n  return `${url}?${search.join('&')}`;\n};\n\nexport const makeFetchOptions = (\n  operation: Operation,\n  body?: FetchBody\n): RequestInit => {\n  const useGETMethod = shouldUseGet(operation);\n\n  const extraOptions =\n    typeof operation.context.fetchOptions === 'function'\n      ? operation.context.fetchOptions()\n      : operation.context.fetchOptions || {};\n\n  return {\n    ...extraOptions,\n    body: !useGETMethod && body ? JSON.stringify(body) : undefined,\n    method: useGETMethod ? 'GET' : 'POST',\n    headers: useGETMethod\n      ? extraOptions.headers\n      : { 'content-type': 'application/json', ...extraOptions.headers },\n  };\n};\n","import { Source, make } from 'wonka';\nimport { Operation, OperationResult } from '../types';\nimport { makeResult, makeErrorResult, mergeResultPatch } from '../utils';\n\nconst asyncIterator =\n  typeof Symbol !== 'undefined' ? Symbol.asyncIterator : null;\nconst decoder = typeof TextDecoder !== 'undefined' ? new TextDecoder() : null;\nconst jsonHeaderRe = /content-type:[^\\r\\n]*application\\/json/i;\nconst boundaryHeaderRe = /boundary=\"?([^=\";]+)\"?/i;\n\ntype ChunkData = { done: false; value: Buffer | Uint8Array } | { done: true };\n\n// NOTE: We're avoiding referencing the `Buffer` global here to prevent\n// auto-polyfilling in Webpack\nconst toString = (input: Buffer | ArrayBuffer): string =>\n  input.constructor.name === 'Buffer'\n    ? (input as Buffer).toString()\n    : decoder!.decode(input as ArrayBuffer);\n\n// DERIVATIVE: Copyright (c) 2021 Marais Rossouw <hi@marais.io>\n// See: https://github.com/maraisr/meros/blob/219fe95/src/browser.ts\nconst executeIncrementalFetch = (\n  onResult: (result: OperationResult) => void,\n  operation: Operation,\n  response: Response\n): Promise<void> => {\n  // NOTE: Guarding against fetch polyfills here\n  const contentType =\n    (response.headers && response.headers.get('Content-Type')) || '';\n  if (!/multipart\\/mixed/i.test(contentType)) {\n    return response.json().then(payload => {\n      onResult(makeResult(operation, payload, response));\n    });\n  }\n\n  let boundary = '---';\n  const boundaryHeader = contentType.match(boundaryHeaderRe);\n  if (boundaryHeader) boundary = '--' + boundaryHeader[1];\n\n  let read: () => Promise<ChunkData>;\n  let cancel = () => {\n    /*noop*/\n  };\n  if (asyncIterator && response[asyncIterator]) {\n    const iterator = response[asyncIterator]();\n    read = iterator.next.bind(iterator);\n  } else if ('body' in response && response.body) {\n    const reader = response.body.getReader();\n    cancel = reader.cancel.bind(reader);\n    read = reader.read.bind(reader);\n  } else {\n    throw new TypeError('Streaming requests unsupported');\n  }\n\n  let buffer = '';\n  let isPreamble = true;\n  let nextResult: OperationResult | null = null;\n  let prevResult: OperationResult | null = null;\n\n  function next(data: ChunkData): Promise<void> | void {\n    if (!data.done) {\n      const chunk = toString(data.value);\n      let boundaryIndex = chunk.indexOf(boundary);\n      if (boundaryIndex > -1) {\n        boundaryIndex += buffer.length;\n      } else {\n        boundaryIndex = buffer.indexOf(boundary);\n      }\n\n      buffer += chunk;\n      while (boundaryIndex > -1) {\n        const current = buffer.slice(0, boundaryIndex);\n        const next = buffer.slice(boundaryIndex + boundary.length);\n\n        if (isPreamble) {\n          isPreamble = false;\n        } else {\n          const headersEnd = current.indexOf('\\r\\n\\r\\n') + 4;\n          const headers = current.slice(0, headersEnd);\n          const body = current.slice(headersEnd, current.lastIndexOf('\\r\\n'));\n\n          let payload: any;\n          if (jsonHeaderRe.test(headers)) {\n            try {\n              payload = JSON.parse(body);\n              nextResult = prevResult = prevResult\n                ? mergeResultPatch(prevResult, payload, response)\n                : makeResult(operation, payload, response);\n            } catch (_error) {}\n          }\n\n          if (next.slice(0, 2) === '--' || (payload && !payload.hasNext)) {\n            if (!prevResult)\n              return onResult(makeResult(operation, {}, response));\n            break;\n          }\n        }\n\n        buffer = next;\n        boundaryIndex = buffer.indexOf(boundary);\n      }\n    }\n\n    if (nextResult) {\n      onResult(nextResult);\n      nextResult = null;\n    }\n\n    if (!data.done && (!prevResult || prevResult.hasNext)) {\n      return read().then(next);\n    }\n  }\n\n  return read().then(next).finally(cancel);\n};\n\nexport const makeFetchSource = (\n  operation: Operation,\n  url: string,\n  fetchOptions: RequestInit\n): Source<OperationResult> => {\n  const maxStatus = fetchOptions.redirect === 'manual' ? 400 : 300;\n  const fetcher = operation.context.fetch;\n\n  return make<OperationResult>(({ next, complete }) => {\n    const abortController =\n      typeof AbortController !== 'undefined' ? new AbortController() : null;\n    if (abortController) {\n      fetchOptions.signal = abortController.signal;\n    }\n\n    let ended = false;\n    let statusNotOk = false;\n    let response: Response;\n\n    Promise.resolve()\n      .then(() => {\n        if (ended) return;\n        return (fetcher || fetch)(url, fetchOptions);\n      })\n      .then((_response: Response | void) => {\n        if (!_response) return;\n        response = _response;\n        statusNotOk = response.status < 200 || response.status >= maxStatus;\n        return executeIncrementalFetch(next, operation, response);\n      })\n      .then(complete)\n      .catch((error: Error) => {\n        if (error.name !== 'AbortError') {\n          const result = makeErrorResult(\n            operation,\n            statusNotOk ? new Error(response.statusText) : error,\n            response\n          );\n\n          next(result);\n          complete();\n        }\n      });\n\n    return () => {\n      ended = true;\n      if (abortController) {\n        abortController.abort();\n      }\n    };\n  });\n};\n"]},"metadata":{},"sourceType":"module"}